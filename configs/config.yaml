# experiment name. defaults to name of training config
experiment: ''
# seed - set to -1 to choose random seed
seed: -1
# set to True for deterministic performance
torch_deterministic: False
## Device config
rl_device: ???
device_id: 0  # 'cuda:?', -1 for 'cpu'

# Disables viewer or camera visualization
viewer: True
imshow_cam: False
# RL Arguments
test: True # False, True
task: Tracing # Catching_TwoStage, Catching_OneStage, Tracking

# make sure to set batch_size, minibatch_size according to num_envs in WireWalkerPPO.yaml
# self.batch_size = self.horizon_length * self.num_actors
# num_actors = num_envs
# default: 
# num_envs: 8
# minibatch_size: 512
# horizon_length: 64

num_envs: 1 # This should be no more than 2x your CPUs (1x is recommended)
# num_envs: 8 # This should be no more than 2x your CPUs (1x is recommended)
wire_eval: False

# used to set checkpoint path
checkpoint_tracking: ''
checkpoint_catching: ''
checkpoint_tracing: 'assets/models/trace.pth'
# checkpoint_tracking: 'assets/models/track.pth'
# checkpoint_catching: 'assets/models/catch_two_stage.pth'

# wandb config
output_name: WireWalker
wandb_mode: "disabled"  # "online" | "offline" | "disabled"
wandb_entity: 'Your_username'
# wandb_project: 'RL_Dcmm_Track_Random'
wandb_project: 'RL_Dcmm_Catch_Random'

# set default task and default training config based on task
# currently we keep the same PPO settings for WireWalker
defaults:
  - train: WireWalkerPPO
  - hydra/job_logging: disabled

# set the directory where the output files get saved
hydra:
  output_subdir: null
  run:
    dir: .
